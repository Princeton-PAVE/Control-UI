# Autonomous Vehicle UI & Control System Plan
## Architecture: React (Frontend) + Flask (Backend/Signaling) + WebRTC (Streaming/Data)

### 1. Executive Summary
This plan outlines the architecture for a low-latency, bi-directional control platform for an autonomous vehicle (AV). The system uses **WebRTC** for real-time video streaming and control data transmission, ensuring minimal lag (<200ms) which is critical for remote operation. **Flask** serves as the Signaling Server and API, while **React** provides the user interface.

### 2. System Architecture

#### A. Components
1.  **The Vehicle (Computer 1):**
    *   **Hardware:** Camera, Motor Controller, Onboard Computer (e.g., Jetson Nano, Raspberry Pi, or x86 Mini PC).
    *   **Software:** Python script running `aiortc` (WebRTC client) and `socketio-client`.
    *   **Role:** Captures video frames, encodes them, streams via WebRTC, and executes control commands received via Data Channels.

2.  **The Server (Intermediary/Endpoint):**
    *   **Software:** Flask + Flask-SocketIO.
    *   **Role:** Acts as the **Signaling Server** to handshake connections between the Vehicle and the User. It also hosts the React build artifacts.
    *   **Deployment:** Can be hosted on the Vehicle itself (for local LAN) or a cloud instance (AWS/DigitalOcean) for remote control over the internet.

3.  **The User Interface (Computer 2):**
    *   **Software:** React.js Web App.
    *   **Role:** Decodes/displays the video stream, captures user inputs (keyboard/gamepad), and sends control packets.

#### B. Data Flow
1.  **Signaling (Handshake):** Vehicle and User both connect to the Flask Server via WebSockets. They exchange SDP (Session Description Protocol) and ICE Candidates to establish a direct Peer-to-Peer (P2P) connection.
2.  **Video Stream (UDP):** Vehicle sends encoded video (H.264/VP8) directly to the User's browser via `RTCPeerConnection`.
3.  **Control Loop (UDP):** User's keyboard inputs -> React -> `RTCDataChannel` -> Vehicle -> Motor Driver.

### 3. Technology Stack

*   **Frontend:** React, Material UI (for layout), `socket.io-client` (signaling), Native WebRTC API.
*   **Backend:** Python Flask, `flask-socketio`, `eventlet` (for async socket handling).
*   **Vehicle Client:** Python, `aiortc` (WebRTC implementation), `opencv-python` (video capture), `gpiozero` or serial libraries (motor control).
*   **Network:** WebRTC (UDP-based for speed), STUN/TURN servers (Google's public STUN is free; Coturn for private TURN).

### 4. Implementation Steps

#### Phase 1: The Signaling Server (Flask)
*   **Goal:** Create a room-based handshake system.
*   **Key Code:**
    *   Initialize `SocketIO(app, cors_allowed_origins="*")`.
    *   Events: `on('offer')`, `on('answer')`, `on('ice-candidate')`.
    *   Logic: When User joins, notify Vehicle. Forward signals between them strictly.

#### Phase 2: The Vehicle Client (Python)
*   **Goal:** Capture video and stream it to a "virtual" peer.
*   **Key Libraries:** `aiortc`, `av`.
*   **Logic:**
    *   Create `RTCPeerConnection`.
    *   Add a video track (Custom class inheriting `VideoStreamTrack` that pulls frames from OpenCV).
    *   Connect to Flask SocketIO.
    *   On `offer` from user, set remote description, create `answer`, and send back.
    *   **Control:** Setup `@pc.on("datachannel")` to listen for JSON packets (e.g., `{"x": 1, "y": 0}`) and map them to motor functions.

#### Phase 3: The React Web App
*   **Goal:** Display video and capture input.
*   **Key Components:**
    *   `<VideoPlayer />`: A component with a `<video autoPlay playsInline muted />` tag.
    *   **Hook:** `useEffect` to initialize the WebRTC connection on mount.
    *   **Input Handling:** Global event listeners for `keydown` and `keyup`. Maintain a state of pressed keys (e.g., `{w: true, a: false}`).
    *   **Transmission:** Send control state every 50ms via `dataChannel.send()` to avoid flooding the network.

#### Phase 4: Safety & Optimization
*   **Heartbeat:** Vehicle must stop if no data is received on the DataChannel for >500ms.
*   **Rate Limiting:** Cap control packets to 20-30Hz.
*   **Latency Management:** Use `RTCBundlePolicy: max-bundle` and VP8 codec for best real-time performance.

### 5. Detailed Code Structure (Mental Model)

**File Structure:**
/project-root
  /server (Flask)
    app.py (Signaling logic)
  /vehicle (Python)
    robot_main.py (aiortc + hardware logic)
  /client (React)
    /src
      components/
        Cockpit.js (Video + Controls)
      services/
        webrtc.js (PeerConnection logic)

### 6. Summary
This architecture avoids the high latency of HTTP/MJPEG streaming by leveraging WebRTC. Flask performs the crucial role of introducing the two computers, after which they talk directly, allowing for high-definition, sub-second video and responsive control.
